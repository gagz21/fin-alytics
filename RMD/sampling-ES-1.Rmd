---
title: "Simulation for risk management:"
subtitle: "Notes on confidence interval estimation for Expected Shortfall"
author: "Bill Foote"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
---

## Imagine

Imagine if we surveyed our management team to guage their preferences and their opinions about the likelihood of events occuring

- How often a customer segment tends to default and how large a default that might be

- the minimum, most likely, maximum of on-time-in-full metrics for vendors by material and service category

- The probability that a low, medium, or high price will occur for the market value of our refined vegetable oil

- The priorities we place on serving (a triage!) customer complaints

Each of these situations pairs outcomes with probabilities, in short a probability distribution. We can even feature priorities as probabilities if we define them the same way as a probability (always positive, all of them add up to one, etc.).

## Tools
  
Tools and thought we will need

- How to make draws from, and use random distributions

- Writing functions with known run-times and verifiable results

- Why we don't use `for` loops

What we will do now

- Write simulations using random number generation
- Explore the jackknife and end up at the bootstrap
- Simulate processes with memory
- Finally, `for` loops!
  
  
## `[d p q r]unif`
  
`runif()`: draws from the uniform distribution (others follow)

  - Build a discrete distributions: Use `sample()`.
  
  - Assign some data to `values`, specify the number of samples to be drawn fromm `values` in `n_samples`, specify probabilities for low, medium, and high values in 'probs', and also direct that we will sample with replacement.
  
  - Count the draws from the three levels sampled using `table()`


```{r}
population_values <- 1:3
n_samples <- 100000
probs <- c(.5, .2, .3)
my_draw <- sample (population_values, n_samples, probs, replace=TRUE)
table(my_draw)
```


## Permutations with `sample()`

`sample()` is powerful -- it works on any object that has a defined `length()`. 

  - Permutations of `values`
  
```{r}
  sample(5)
  sample(1:6)
```
   - Use `replicate()` with each `sample()` in a vector
   
```{r }
  replicate(3,sample(c("Curly","Larry","Moe","Shemp")))
```
  
   - Or generate random lists
  
```{r }
  sample(list("A",3,sum))
```

## Resampling with `sample()`

When we resample from any existing distribution we generate the **bootstrap** family of estimators. 

- The `bootstrap_resample` function just draws one sample of size `n_sample = 3` from the data.
  
- Then we `replicate` this sampling so many times (5 here)

```{r }
bootstrap_resample <- function (data, n_sample) sample(data, n_sample, replace=TRUE) 
t(replicate(5, bootstrap_resample (6:10, 3)))
```

The `t`ranspose simply arranges the samples in columns with the replications in rows.


## Expected shortfall test

Suppose management, or even more so wary investors, wanted to understand how much capital they could probably need to have to cover loss exposures. So far we have been using value at risk to set the threshold for the expected shortfall as a gross risk-informed measure of the amount of capital required against potential losses. To do this we would calculate an estimate of the range within which we could expect the expected shortfall to be, say, 95\% of the time. The range would then identify at least (lower bound) and at most (upper bound) the amount of capital needed for a given probability that our expresses our confidence.

First, we get some data, here exchange rates, and calculate percentage changes

```{r}
exrates <- na.omit(read.csv("data/exrates.csv", header = TRUE))
exrates.r <- diff(log(as.matrix(exrates[, -1]))) * 100
```

Then we build a helper function to calculated the expected shortfall once.

```{r}
ES_calc <- function(data, prob){
  data <- -as.matrix(data)
  return(mean(data[data > quantile(data, prob),]))
}
ES_1 <- ES_calc(exrates.r[,1], 0.95)
ES_1
```

Next, we take a sample of exchange rate returns (250 of them at random), calculate the ES, and do this a lot of times (1000 for now).

```{r}
ES_sample <- replicate(10000, ES_calc(bootstrap_resample (-exrates.r[,1], 250), 0.95))
summary(ES_sample)
```

Finally, we calculate the upper and lower bounds using the same `quantile()` function as we did in finding a value at risk threshold for the expected shortfall.

```{r}
(q_0.025 <- quantile(ES_sample, 0.025))
(q_0.975 <- quantile(ES_sample, 0.975))
(q_0.500 <- quantile(ES_sample, 0.500))
```
 
 A plot shows off our handiwork.
 
```{r}
ES_sample_df <- data.frame(ES = ES_sample )
ES_title <- "Expected Shortfall USD-EUR 95%"
library(ggplot2)
#ES_sample_df %>%
  ggplot(ES_sample_df, aes(x = ES)) + geom_density() + ggtitle(ES_title) + geom_vline(xintercept = q_0.025, colour="red") + geom_vline(xintercept = q_0.975, colour="red") + geom_vline(xintercept = q_0.500, color = "blue")
```
